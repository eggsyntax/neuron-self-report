# Neural Network Introspection System: Project Recreation Plan

This document provides instructions for creating a neural network introspection system that enables transformer models to "self-report" their internal activation values. The system trains models to predict specific MLP neuron activations from their own representations, creating a form of introspective capability.

## Project Overview

The Neural Network Introspection System enables a novel approach to interpretability by using a model's own representations to predict its internal activation values. Rather than using external probes, this approach leverages the model's existing knowledge to understand its internal states.

The core workflow consists of:

1. **Neuron Selection**: Identifying neurons with interesting activation patterns
2. **Dataset Generation**: Creating datasets mapping text inputs to neuron activation values
3. **Model Training**: Fine-tuning models to predict neuron activations
4. **Evaluation & Analysis**: Assessing performance and investigating what is learned

## System Architecture

Build a modular system with these primary components:

1. **NeuronScanner**: For identifying interesting neurons
2. **ActivationDatasetGenerator**: For creating activation datasets
3. **ActivationPredictor**: For predicting activations using different head types
4. **PredictorTrainer**: For training with monitoring capabilities
5. **Main Pipeline**: Orchestrating the entire workflow

## Implementation Guide

### 1. Project Setup

Create a project with the following structure:
```
neuron_self_report/
├── scanner.py
├── dataset.py
├── architecture.py
├── trainer.py
├── mech_interp-notebooks/
├── neuron_self_report.py
└── README.md
```

Install required dependencies if they aren't already installed:
- PyTorch (1.10+)
- TransformerLens
- HuggingFace Transformers
- NumPy, Matplotlib, Pandas
- tqdm
- scikit-learn

### 2. Dataset Generation Module

Create an `ActivationDatasetGenerator` class that:
- Takes a transformer model as input
- Extracts activation values for specified neurons
- Creates datasets mapping text inputs to neuron activations
- Supports both classification (binned) and regression (continuous) approaches
- Balances datasets across activation ranges
- Saves/loads datasets to/from CSV files with metadata (confirmed suitable for project scale).

Implementation should:
- Support different input text sources (synthetic [default], user-provided).
- For synthetic data generation:
  - Prioritize diversity to prevent overfitting. Aim for at least 2000 distinct items.
  - Data should be *roughly* in-distribution for human-produced text (e.g., sentences from multiple unrelated Wikipedia articles are acceptable; strings of random words are not).
  - May use diverse datasets from sources like HuggingFace or Kaggle, ensuring the dataset size is manageable (e.g., <= 10,000 rows, randomize and truncate if larger).
- Extract activations for specific token positions (last token [default], specific index)
- Include robust metadata with activation statistics

### 3. Neuron Selection Module

Create a `NeuronScanner` class that:
- Takes a transformer model as input (gpt2-small by default). All models will be from the TransformerLens library. Throughout the project, use the TransformerLens library for tasks to which it is suited, and otherwise use the HuggingFace library. When the desired functionality is available in neither, use pytorch functionality directly.
- Processes text samples from a dataset (typically the one generated by the previous module) to extract neuron activations
- Calculates statistics (variance, activation range) for each neuron
- Scores neurons based on these statistics.
  - Candidate neurons are ones which are 0 at least 30% of the time and non-0 at least 30% of the time.
  - Score candidate neurons using a weighted sum of their variance and range (default weights for equal priority, higher is better for both).
- Identifies the most "interesting" neurons
- Provides visualization capabilities for activation distributions
- Shows the user the top 5 candidates, their layer and position and statistics, and lets the user choose one.

This module should:
- Support scanning across all layers or within specific layer ranges
- Generate visualizations showing activation patterns
- Return detailed statistics about selected neurons

### 4. Architecture Module

Create an `ActivationPredictor` class that:
- Takes a transformer model as the base model
- Adds prediction heads of various types:
  - **Regression Head**: For predicting continuous activation values.
  - **Classification Head**: For predicting discretized activation values.
  - **Token Prediction Head**: For using the model's token prediction pathway. This head will support two modes:
    1.  **Binary Output**: Predict one of two tokens: 'on' (if target neuron activation > 0) or 'off' (if target neuron activation == 0).
    2.  **Single-Digit Output**: Predict a single-digit token ('0' through '9'). These tokens represent 10 equidistant points spanning the `mean ± 2*std_dev` range of the target neuron's activations in the current dataset. The loss function maps the predicted token to its corresponding numeric value for comparison with the actual activation.

The architecture should:
- Use the model's own representations to predict activations
- Support different feature extraction points (specific layers)
- Handle various token positions (last token, specific position)
- Include proper normalization and denormalization of predictions
- Provide evaluation metrics appropriate to each head type

### 5. Training Module

Create a `PredictorTrainer` class that:
- Handles the training process with appropriate loss functions
- Implements various model unfreezing strategies:
  - No unfreezing (head-only training)
  - Complete unfreezing
  - Unfreezing layers after the target neuron
  - Selective component unfreezing
- Includes monitoring capabilities:
  - Activation distribution monitoring:
    - Comprehensive text-based logging of activation statistics (mean, variance, sparsity, etc.).
    - Visualizations of key metrics (e.g., how mean and standard deviation of activations change during training, particularly relevant if the layer containing the target neuron is unfrozen).
- Generates comprehensive visualizations of training results.

Key features should include:
- Early stopping.
- Validation during training.
- Visualization generation.
- Parameter freezing/unfreezing control.
- Detailed logging and metrics tracking, including integration with Weights & Biases (credentials loaded from environment variables).

### 6. Main Pipeline

Create a `neuron_self_report.py` script that:
- Loads options from a JSON configuration file. All parameters should have sensible defaults. Key configurable parameters include:
  - `model_name`: Name of the TransformerLens model (e.g., "gpt2-small").
  - `neuron_layer`: Layer index of the target neuron.
  - `neuron_index`: Index of the target neuron within the layer.
  - `hook_point`: Specific hook point for activations (e.g., "mlp_out").
  - `dataset_path`: Path to a user-provided dataset (optional).
  - `learning_rate`: Learning rate for training.
  - `batch_size`: Batch size for training.
  - `output_type`: Type of prediction head and task (`regression`, `classification`, `token_binary`, `token_digit`).
  - `data_source`: `synthetic` (generate data) or `provided` (use `dataset_path`).
  - `token_position`: Token position for loss calculation (e.g., `last`, or a specific integer index).
  - `num_samples`: Total number of samples to use/generate (e.g., 2000; split 75% train / 25% test).
  - `output_dir`: Directory for saving results (default: `output/` within `code3/`). Previous run's output in this directory will be moved to a timestamped subdirectory of `previous-outputs/`.
  - `epochs`: Number of training epochs (default: 10).
  - `unfreeze_strategy`: Model unfreezing approach (`head_only`, `all_layers`, `layers_after_target`, `selective_components`).
  - `device`: Computation device (default: `mps`; options: `cpu`, `cuda`).
- Orchestrates the end-to-end pipeline.
- Handles experimental configurations.
- Generates final visualizations and reports.
- Saves results in consistent formats.

The pipeline should integrate all components:
1. Generate appropriate datasets
2. Select interesting neurons
3. Create a prediction model
4. Train the model with monitoring
5. Evaluate and visualize results

### 7. Mechanistic Interpretability Scripts

NOTE - these will not be added until later.
Add Jupyter notebooks for advanced analysis:
- **Linear Weights Analysis**: Compare prediction weights with neuron weights
- **Activation Patching**: Assess causal impact of neurons on predictions

These analyses provide deeper insights into what the model learns.

## Experimental Configurations

The system should support several key experimental configurations:

1. **Token Pathway Training**: Training the model to output activation values through its token prediction path
2. **Basic Linear Probe**: Training a regression head with the base model frozen
3. **Self-Modification Testing**: Unfreezing the entire model to test whether it learns to regularize neurons
4. **Causal Testing**: Unfreezing only layers after the target neuron

## Evaluation & Analysis

Implement evaluation methods that:
- Calculate appropriate metrics (MSE, correlation)
- Generate visualizations comparing predictions to actual values
- Analyze how predictions change with various inputs
- Compare weight patterns between prediction heads and target neurons

## Additional Considerations

1. **Directory** The root directory of the project is `neuron_self_report`; its absolute location is '/Users/egg/Documents/ai-safety/Research Projects/neuron_self_report' (if that doesn't exist, check with the user). This implementation will be placed in a 'code3/' directory within that root directory. There is no need to consider files outside of the 'code3/' directory (there are records of past implementations, eg 'code1/'; these should be ignored).
2. **Error Handling**: Robust error handling throughout
3. **Documentation**: Comprehensive docstrings and README.md.
4. **Logging**: Informative logging throughout the pipeline, integrated with Weights & Biases.
5. **Visualization**: Clear, publication-quality visualizations.
6. **Testing**: Thorough unit and integration tests. Unless otherwise directed, please create unit tests before writing the code, carefully considering what functionality needs to be tested. Where it's reasonable to do so, favor property testing and fuzz testing. In cases where these seem overly time-consuming or difficult, fall back to more typical unit tests.
7. **TransformerLens Backpropagation**: Be mindful that with TransformerLens, backpropagation information attached to PyTorch modules or tensors can sometimes be lost during copying or manipulation. Ensure gradients flow as expected.
8. **Design Principle - Readability over DRY**: Prioritize readability and clarity in the codebase. It's acceptable to have some code duplication if it makes different modules or cases (e.g., for regression, classification, token prediction heads) easier to understand and maintain independently.

## Conclusion

This plan outlines how to create a Neural Network Introspection System that enables transformer models to predict their own internal activation values. By implementing the components described here, you'll build a comprehensive system for exploring how neural networks can understand and report their own internal states.

The approach offers a novel perspective on interpretability by leveraging the model's own representations rather than external probes. This can provide insights into both the specific neurons being predicted and the model's capacity for self-understanding.
